# Same as config 1, but with 64 epochs. This should learn something
vocab_size: 2000
embedding_size: 64
num_layers: 2
n_units: 256
dropout_prob: 0.2
learning_rate: 1e-3
lr_decay: 1e-6
epochs: 64
batch_size: 256
reg_coeff: 1e-5
